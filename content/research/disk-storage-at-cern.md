---
docType: "publication"
title: "Disk storage at CERN"
date: 2015-12-01T00:00:00+00:00
location: "CERN"
authors: ["L. Mascetti", "E. Cano", "B. Chan", "X. Espinal", "A. Fiorot", "H.G.Labrador", "J. Iven", "M. Lamanna", "G.Lo Presti", "JT. Mo≈õcicki", "et al"]
publisher: "J.Phys.Conf.Ser. 664 (2015) no.4, 042035"
links:
  - type: "pdf"
    href: "https://inspirehep.net/record/1413866/files/jpconf15_664_042035.pdf"

---

CERN IT DSS operates the main storage resources for data taking and physics analysis mainly via three system: AFS, CASTOR and EOS. The total usable space available on disk for users is about 100 PB (with relative ratios 1:20:120). EOS actively uses the two CERN Tier0 centres (Meyrin and Wigner) with 50:50 ratio. IT DSS also provide sizeable on-demand resources for IT services most notably OpenStack and NFS-based clients: this is provided by a Ceph infrastructure (3 PB) and few proprietary servers (NetApp). We will describe our operational experience and recent changes to these systems with special emphasis to the present usages for LHC data taking, the convergence to commodity hardware (nodes with 200-TB each with optional SSD) shared across all services. We also describe our experience in coupling commodity and home-grown solution (e.g. CERNBox integration in EOS, Ceph disk pools for AFS, CASTOR and NFS) and finally the future evolution of these systems for WLCG and beyond
